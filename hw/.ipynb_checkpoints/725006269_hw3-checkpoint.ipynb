{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2017\n",
    "\n",
    "\n",
    "# Homework 3:  Classification Cook-off: Naive Bayes vs Rocchio (plus a little bit of recommenders)\n",
    "\n",
    "### 100 points [5% of your final grade]\n",
    "\n",
    "### Due: Wednesday, March 29 by 11:59pm\n",
    "\n",
    "*Goals of this homework:* Hands-on practice building and evaluating classifiers.\n",
    "\n",
    "*Submission Instructions:* To submit your homework, rename this notebook as YOUR_UIN_hw3.ipynb. Submit this notebook via eCampus. Your notebook should be completely self-contained, with the results visible in the notebook. \n",
    "\n",
    "*Late submission policy:* For this homework, you may use up to three of your late days, meaning that no submissions will be accepted after Saturday April 1 at 11:59pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Yelp review data\n",
    "\n",
    "In this assignment, given a Yelp review, your task is to implement two classifiers to predict if the business category of this review is \"food-relevant\" or not, **only based on the review text**. The data is from the [Yelp Dataset Challenge](https://www.yelp.com/dataset_challenge).\n",
    "\n",
    "## Build the training data\n",
    "\n",
    "First, you will need to download this data file as your training data: [training_data.json](https://drive.google.com/open?id=0B_13wIEAmbQMdzBVTndwenoxQlk) \n",
    "\n",
    "The training data file includes 40,000 Yelp reviews. Each line is a json-encoded review, and **you should only focus on the \"text\" field**. As same as in homework 1, you should tokenize the review text by using the regular expression \"\\W+\" (we discussed it in [this Piazza post](https://piazza.com/class/ixkk1fy863r1vs?cid=29). Do NOT remove stop words. **Do casefolding but no stemming**.\n",
    "\n",
    "The label (class) information of each review is in the \"label\" field. It is **either \"Food-relevant\" or \"Food-irrelevant\"**.\n",
    "\n",
    "## Testing data\n",
    "\n",
    "We provide 100 yelp reviews here: [testing_data.json](https://drive.google.com/open?id=0B_13wIEAmbQMbXdyTkhrZDN4Wms). The testing data file has the same format as the training data file. Again, you can get the label informaiton in the \"label\" field. Only use it when you evalute your classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Naive Bayes classifier [35 points]\n",
    "\n",
    "In this part, you will implement a Naive Bayes classifier, which outputs the probabilities that a given review belongs to each class.\n",
    "\n",
    "Use a mixture model that mixes the probability from the document with the general collection frequency of the word. **You should use lambda = 0.7**. Be careful about the decimal rounding since multiplying many probabilities can generate a tiny value. We will not grade on the exact probability value, so feel free to change to logorithm summation (it's not required, though). If the tie case happens, **always go to the \"Food-irrelevant\" side**.\n",
    "\n",
    "### What to report\n",
    "\n",
    "* For the entire testing dataset, report the overall accuracy.\n",
    "* For the class \"Food-relevant\", report the precision and recall.\n",
    "* For the class \"Food-irrelevant\", report the precision and recall.\n",
    "\n",
    "We will also grade on the quality of your code. So make sure that your code is clear and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###RESULTS FOR NAIVE BAYES###\n",
      "\n",
      "\n",
      "Accuracy: 0.89\n",
      "Precision - relevant:  0.901408450704\n",
      "Recall - relevant:  0.941176470588\n",
      "Precision - irrelevant:  0.862068965517\n",
      "Recall - irrelevant:  0.78125\n"
     ]
    }
   ],
   "source": [
    "# Build the naive bayes classifier\n",
    "# Insert as many cells as you want\n",
    "import json\n",
    "import collections\n",
    "import math\n",
    "import re\n",
    "food_rel = collections.defaultdict(int)\n",
    "food_irrel = collections.defaultdict(int)\n",
    "count_food_rel = 0\n",
    "count_food_irrel = 0\n",
    "const_lambda = 0.7\n",
    "with open('training_data.json') as f:\n",
    "    for line in f:\n",
    "        j_content = json.loads(line)\n",
    "        if j_content['type'] == 'review':\n",
    "            if j_content['label'] == 'Food-relevant':\n",
    "                for x in re.split('\\W+', j_content['text']):\n",
    "                    word = x.lower()\n",
    "                    food_rel[word] += 1\n",
    "                    count_food_rel += 1\n",
    "            elif j_content['label'] == 'Food-irrelevant':\n",
    "                for x in re.split('\\W+', j_content['text']):\n",
    "                    word = x.lower()\n",
    "                    food_irrel[word] += 1\n",
    "                    count_food_irrel += 1\n",
    "accuracy = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "tp_relevant = 0\n",
    "tn_relevant = 0\n",
    "fp_relevant = 0\n",
    "fn_relevant = 0\n",
    "tp_irrelevant = 0\n",
    "tn_irrelevant = 0\n",
    "fp_irrelevant = 0\n",
    "fn_irrelevant = 0\n",
    "with open('testing_data.json') as f:\n",
    "    for line in f:\n",
    "        prob_food_rel = 0.0\n",
    "        prob_food_irrel = 0.0\n",
    "        j_test_content = json.loads(line)\n",
    "        if j_test_content['type'] == 'review':\n",
    "            for x in re.split('\\W+', j_test_content['text']):\n",
    "                word = x.lower()\n",
    "                try:\n",
    "                    prob_food_rel += math.log((const_lambda * food_rel[word]/count_food_rel + (1-const_lambda)*(food_irrel[word] + food_rel[word])/(count_food_irrel + count_food_rel)))\n",
    "                except:\n",
    "                    prob_food_rel = prob_food_rel\n",
    "                try:\n",
    "                    prob_food_irrel += math.log((const_lambda * food_irrel[word]/count_food_irrel + (1-const_lambda)*(food_irrel[word] + food_rel[word])/(count_food_irrel + count_food_rel)))\n",
    "                except:\n",
    "                    prob_food_irrel = prob_food_irrel\n",
    "        if prob_food_rel > prob_food_irrel:\n",
    "            if  j_test_content['label'] == 'Food-relevant':\n",
    "                correct += 1\n",
    "                tp_relevant += 1\n",
    "                tn_irrelevant += 1\n",
    "            if j_test_content['label'] == 'Food-irrelevant':\n",
    "                fp_relevant += 1\n",
    "                fn_irrelevant += 1\n",
    "        else:\n",
    "            if j_test_content['label'] == 'Food-irrelevant':\n",
    "                correct += 1\n",
    "                tn_relevant += 1\n",
    "                tp_irrelevant += 1\n",
    "            if j_test_content['label'] == 'Food-relevant':\n",
    "                fn_relevant += 1\n",
    "                fp_irrelevant += 1\n",
    "        total += 1\n",
    "        \n",
    "print \"###RESULTS FOR NAIVE BAYES###\"\n",
    "print \"\\n\"\n",
    "print \"Accuracy:\", float(correct)/float(total)\n",
    "print \"Precision - relevant: \", float(tp_relevant)/float(tp_relevant + fp_relevant)\n",
    "print \"Recall - relevant: \", float(tp_relevant)/float(tp_relevant + fn_relevant)\n",
    "print \"Precision - irrelevant: \", float(tp_irrelevant)/float(tp_irrelevant + fp_irrelevant)\n",
    "print \"Recall - irrelevant: \", float(tp_irrelevant)/float(tp_irrelevant + fn_irrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply your classifier on the test data. Report the results.\n",
    "# Insert as many cells as you want\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Rocchio classifier [35 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, your job is to implement a Rocchio classifier for \"food-relevant vs. food-irrelevant\". You need to aggregate all the reviews of each class, and find the center. **Use the normalized raw term frequency**.\n",
    "\n",
    "\n",
    "### What to report\n",
    "\n",
    "* For the entire testing dataset, report the overall accuracy.\n",
    "* For the class \"Food-relevant\", report the precision and recall.\n",
    "* For the class \"Food-irrelevant\", report the precision and recall.\n",
    "\n",
    "We will also grade on the quality of your code. So make sure that your code is clear and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### RESULTS FOR ROCHHIO #####\n",
      "\n",
      "\n",
      "Using  Manhattan Distance: \n",
      "Accuracy(Manhattan):  0.72\n",
      "Precision(Manhattan) - relevant:  0.722222222222\n",
      "Recall(Manhattan) - relevant:  0.955882352941\n",
      "Precision(Manhattan) - irrelevant:  0.7\n",
      "Recall(Manhattan) - irrelevant:  0.21875\n",
      "\n",
      "\n",
      "Using Euclidean Distance: \n",
      "Accuracy(Euclidean):  0.65\n",
      "Precision(Euclidean) - relevant:  0.8\n",
      "Recall(Euclidean) - relevant:  0.647058823529\n",
      "Precision(Euclidean) - irrelevant:  0.466666666667\n",
      "Recall(Euclidean) - irrelevant:  0.65625\n"
     ]
    }
   ],
   "source": [
    "# Build the Rocchio classifier\n",
    "# Insert as many cells as you want\n",
    "centroid_food_rel = collections.defaultdict(float)\n",
    "centroid_food_irrel = collections.defaultdict(float)\n",
    "count_food_rel_reviews = 0\n",
    "count_food_irrel_reviews = 0\n",
    "arr_rel = []\n",
    "arr_irrel = []\n",
    "index_rel = 0\n",
    "index_irrel = 0\n",
    "word_set=set()\n",
    "\n",
    "def normalize(dictionary):\n",
    "    result = 0.0\n",
    "    for key in dictionary:\n",
    "        result += dictionary[key]**2\n",
    "    result = math.sqrt(result)\n",
    "    for key in dictionary:\n",
    "        dictionary[key] = float(dictionary[key])/float(result)\n",
    "    return dictionary\n",
    "\n",
    "with open('training_data.json') as f:\n",
    "    for line in f:\n",
    "        j_content = json.loads(line)\n",
    "        if j_content['type'] == 'review':\n",
    "            if j_content['label'] == 'Food-relevant':\n",
    "                arr_rel.append(collections.defaultdict(float))\n",
    "                for x in re.split('\\W+', j_content['text']):\n",
    "                    word = x.lower()\n",
    "                    if word != '':\n",
    "                        word_set.add(word)\n",
    "                    arr_rel[index_rel][word] += 1.0\n",
    "                arr_rel[index_rel] = normalize(arr_rel[index_rel])\n",
    "                index_rel += 1\n",
    "                \n",
    "                count_food_rel_reviews += 1\n",
    "            if j_content['label'] == 'Food-irrelevant':\n",
    "                arr_irrel.append(collections.defaultdict(float))\n",
    "                for x in re.split('\\W+', j_content['text']):\n",
    "                    word = x.lower()\n",
    "                    if word != '':\n",
    "                        word_set.add(word)\n",
    "                    arr_irrel[index_irrel][word] += 1.0\n",
    "                arr_irrel[index_irrel] = normalize(arr_irrel[index_irrel])\n",
    "                index_irrel += 1\n",
    "                count_food_irrel_reviews += 1\n",
    "for index in xrange(len(arr_rel)):\n",
    "    for key in arr_rel[index]:\n",
    "        centroid_food_rel[key] += arr_rel[index][key]\n",
    "for index in xrange(len(arr_irrel)):\n",
    "    for key in arr_irrel[index]:\n",
    "        centroid_food_irrel[key] += arr_irrel[index][key]\n",
    "for key in centroid_food_rel:\n",
    "    centroid_food_rel[key] = float(centroid_food_rel[key])/float(count_food_rel_reviews)\n",
    "for key in centroid_food_irrel:\n",
    "    centroid_food_irrel[key] = float(centroid_food_irrel[key])/float(count_food_irrel_reviews)\n",
    "\n",
    "correct = 0.0\n",
    "correct_euc = 0.0\n",
    "total = 0.0\n",
    "tp_relevant_rocchio_manhattan = 0\n",
    "tn_relevant_rocchio_manhattan = 0\n",
    "fp_relevant_rocchio_manhattan = 0\n",
    "fn_relevant_rocchio_manhattan = 0\n",
    "tp_irrelevant_rocchio_manhattan = 0\n",
    "tn_irrelevant_rocchio_manhattan = 0\n",
    "fp_irrelevant_rocchio_manhattan = 0\n",
    "fn_irrelevant_rocchio_manhattan = 0\n",
    "tp_relevant_rocchio_euclidean = 0\n",
    "tn_relevant_rocchio_euclidean = 0\n",
    "fp_relevant_rocchio_euclidean = 0\n",
    "fn_relevant_rocchio_euclidean = 0\n",
    "tp_irrelevant_rocchio_euclidean = 0\n",
    "tn_irrelevant_rocchio_euclidean = 0\n",
    "fp_irrelevant_rocchio_euclidean = 0\n",
    "fn_irrelevant_rocchio_euclidean = 0\n",
    "with open('testing_data.json') as f:\n",
    "    for line in f:\n",
    "        manhattan_distance_relevant = 0.0\n",
    "        manhattan_distance_irrelevant = 0.0\n",
    "        euclidean_distance_relevant = 0.0\n",
    "        euclidean_distance_irrelevant = 0.0\n",
    "        j_test_content = json.loads(line)\n",
    "        document_vector = collections.defaultdict(float)\n",
    "        if j_test_content['type'] == 'review':\n",
    "            for x in re.split('\\W+', j_test_content['text']):\n",
    "                word = x.lower()\n",
    "                document_vector[word] += 1\n",
    "        magnitude_document_vector = 0.0\n",
    "        for key in document_vector:\n",
    "            magnitude_document_vector += document_vector[key] ** 2\n",
    "        magnitude_document_vector = math.sqrt(magnitude_document_vector)\n",
    "        for key in document_vector:\n",
    "            document_vector[key] = float(document_vector[key])/float(magnitude_document_vector)\n",
    "        \n",
    "        for word in word_set:\n",
    "            d1 = 0.0\n",
    "            d2 = 0.0\n",
    "            if word in centroid_food_rel:\n",
    "                d1 = centroid_food_rel[word]\n",
    "            if word in document_vector:\n",
    "                d2 = document_vector[word]\n",
    "            euclidean_distance_relevant += (d1-d2) ** 2\n",
    "            manhattan_distance_relevant += abs(d1 - d2)\n",
    "        \n",
    "        for word in word_set:\n",
    "            d1 = 0.0\n",
    "            d2 = 0.0\n",
    "            if word in centroid_food_irrel:\n",
    "                d1 = centroid_food_irrel[word]\n",
    "            if word in document_vector:\n",
    "                d2 = document_vector[word]\n",
    "            euclidean_distance_irrelevant += (d1-d2) ** 2\n",
    "            manhattan_distance_irrelevant += abs(d1 - d2)\n",
    "        if manhattan_distance_relevant < manhattan_distance_irrelevant:\n",
    "            if j_test_content['label'] == 'Food-relevant':\n",
    "                correct += 1.0\n",
    "                tp_relevant_rocchio_manhattan += 1\n",
    "                tn_irrelevant_rocchio_manhattan += 1\n",
    "            if j_test_content['label'] == 'Food-irrelevant':\n",
    "                fp_relevant_rocchio_manhattan += 1\n",
    "                fn_irrelevant_rocchio_manhattan += 1\n",
    "        else:\n",
    "            if j_test_content['label'] == 'Food-irrelevant':\n",
    "                correct += 1.0\n",
    "                tn_relevant_rocchio_manhattan += 1\n",
    "                tp_irrelevant_rocchio_manhattan += 1\n",
    "            if j_test_content['label'] == 'Food-relevant':\n",
    "                fn_relevant_rocchio_manhattan += 1\n",
    "                fp_irrelevant_rocchio_manhattan += 1\n",
    "        if euclidean_distance_relevant < euclidean_distance_irrelevant:\n",
    "            if j_test_content['label'] == 'Food-relevant':\n",
    "                correct_euc += 1.0\n",
    "                tp_relevant_rocchio_euclidean += 1\n",
    "                tn_irrelevant_rocchio_euclidean += 1\n",
    "            if j_test_content['label'] == 'Food-irrelevant':\n",
    "                fp_relevant_rocchio_euclidean += 1\n",
    "                fn_irrelevant_rocchio_euclidean += 1\n",
    "        else:\n",
    "            if j_test_content['label'] == 'Food-irrelevant':\n",
    "                correct_euc += 1.0\n",
    "                tn_relevant_rocchio_euclidean += 1\n",
    "                tp_irrelevant_rocchio_euclidean += 1\n",
    "            if j_test_content['label'] == 'Food-relevant':\n",
    "                fn_relevant_rocchio_euclidean += 1\n",
    "                fp_irrelevant_rocchio_euclidean += 1\n",
    "        total += 1.0\n",
    "\n",
    "print \"##### RESULTS FOR ROCHHIO #####\"\n",
    "print \"\\n\"\n",
    "print \"Using  Manhattan Distance: \"\n",
    "print \"Accuracy(Manhattan): \", float(correct)/float(total)\n",
    "print \"Precision(Manhattan) - relevant: \", float(tp_relevant_rocchio_manhattan)/float(tp_relevant_rocchio_manhattan + fp_relevant_rocchio_manhattan)\n",
    "print \"Recall(Manhattan) - relevant: \", float(tp_relevant_rocchio_manhattan)/float(tp_relevant_rocchio_manhattan + fn_relevant_rocchio_manhattan)\n",
    "print \"Precision(Manhattan) - irrelevant: \", float(tp_irrelevant_rocchio_manhattan)/float(tp_irrelevant_rocchio_manhattan + fp_irrelevant_rocchio_manhattan)\n",
    "print \"Recall(Manhattan) - irrelevant: \", float(tp_irrelevant_rocchio_manhattan)/float(tp_irrelevant_rocchio_manhattan + fn_irrelevant_rocchio_manhattan)\n",
    "print \"\\n\"\n",
    "print \"Using Euclidean Distance: \"\n",
    "print \"Accuracy(Euclidean): \", float(correct_euc)/float(total)\n",
    "print \"Precision(Euclidean) - relevant: \", float(tp_relevant_rocchio_euclidean)/float(tp_relevant_rocchio_euclidean + fp_relevant_rocchio_euclidean)\n",
    "print \"Recall(Euclidean) - relevant: \", float(tp_relevant_rocchio_euclidean)/float(tp_relevant_rocchio_euclidean + fn_relevant_rocchio_euclidean)\n",
    "print \"Precision(Euclidean) - irrelevant: \", float(tp_irrelevant_rocchio_euclidean)/float(tp_irrelevant_rocchio_euclidean + fp_irrelevant_rocchio_euclidean)\n",
    "print \"Recall(Euclidean) - irrelevant: \", float(tp_irrelevant_rocchio_euclidean)/float(tp_irrelevant_rocchio_euclidean + fn_irrelevant_rocchio_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply your classifier on the test data. Report the results.\n",
    "# Insert as many cells as you want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Naive Bayes vs. Rocchio [20 points]\n",
    "\n",
    "Which method gives the better results? In terms of what? How did you compare them? Can you explain why you observe what you do? Write 1-3 paragraphs below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results for Naive Bayes:\n",
    "\n",
    "Accuracy: 0.89, Precision - relevant:  0.901408450704, Recall - relevant:  0.941176470588, Precision - irrelevant:  0.862068965517, Recall - irrelevant:  0.78125\n",
    "\n",
    "\n",
    "Results for Rocchio using Euclidean Distance:\n",
    "\n",
    "Accuracy(Euclidean):  0.65, Precision(Euclidean) - relevant:  0.8, Recall(Euclidean) - relevant:  0.647058823529, Precision(Euclidean) - irrelevant:  0.466666666667, Recall(Euclidean) - irrelevant:  0.65625\n",
    "\n",
    "From our results, we can clearly see that Naive Bayes gives much better accuracy, precision and recall than Rocchio. This is because Rocchio cannot handle nonconvex, multimodal classes. Let's say in Rocchio we have two classes, A and B. For A class, the points are far apart on either sides of the positive Y axis (some points are on far right of positive side of the Y-axis and some points are on far left on the negative side of the Y-axis). While for B class, the points are evenly distributed close to the negative Y-axis. Now we are given a point O to classify which is much closer to B. But by Rocchio, O is much closer to centroid of A class than to B class. So, Rocchio misclassifies this point. But such kind of errors do not happen in Naive Bayes as it considers the maximum posteriori class.\n",
    "\n",
    "Hence, Naive Bayes gives a much better accuracy than Rocchio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Recommenders [10 points]\n",
    "\n",
    "Finally, since we've begun our discussion of recommenders, let's do a quick problem too:\n",
    "\n",
    "The table below is a utility matrix, representing the ratings, on a 1–5 star scale, of eight items, *a* through *h*, by three users *A*, *B*, and *C*. \n",
    "<pre>\n",
    "\n",
    "  | a  b  c  d  e  f  g  h\n",
    "--|-----------------------\n",
    "A | 4  5     5  1     3  2\n",
    "B |    3  4  3  1  2  1\n",
    "C | 2     1  3     4  5  3\n",
    "\n",
    "</pre>\n",
    "\n",
    "Compute the following from the data of this matrix.\n",
    "\n",
    "(a) Treating the utility matrix as boolean, compute the Jaccard distance between each pair of users.\n",
    "\n",
    "(b) Repeat Part (a), but use the cosine distance.\n",
    "\n",
    "(c) Treat ratings of 3, 4, and 5 as 1 and 1, 2, and blank as 0. Compute the Jaccard distance between each pair of users.\n",
    "\n",
    "(d) Repeat Part (c), but use the cosine distance.\n",
    "\n",
    "(e) Normalize the matrix by subtracting from each nonblank entry the average\n",
    "value for its user.\n",
    "\n",
    "(f) Using the normalized matrix from Part (e), compute the cosine distance\n",
    "between each pair of users.\n",
    "\n",
    "(g) Which of the approaches above seems most reasonable to you? Give a one or two sentence argument supporting your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add your answer here:**\n",
    "\n",
    "(a) \n",
    "Jaccard (A,B) = (0+1+0+1+1+0+1+0)/8 = 4/8 = 1/2\n",
    "\n",
    "Jaccard (A,C) = (1+0+0+1+0+0+1+1)/8 = 4/8 = 1/2\n",
    "\n",
    "Jaccard (B,C) = (0+0+1+1+0+1+1+0)/8 = 4/8 = 1/2\n",
    "\n",
    "(b)\n",
    "Cosine(A,B) = 4/sqrt(6) * sqrt(6) = 4/6 = 2/3\n",
    "\n",
    "Cosine(A,C) = 4/sqrt(6) * sqrt(6) = 2/3\n",
    "\n",
    "Cosine(B,C) = 4/sqrt(6) * sqrt(6) = 2/3\n",
    "\n",
    "\n",
    "(c) \n",
    "\n",
    "This is the modified matrix which we use for part(c) and part(d)\n",
    "\n",
    "    a   b   c   d   e   f   g   h\n",
    "    \n",
    "    1   1   0   1   0   0   1   0    A \n",
    "    \n",
    "    0   1   1   1   0   0   0   0    B \n",
    "        \n",
    "    0   0   0   1   0   1   1   1    C \n",
    "   \n",
    "Jaccard (A,B) = (0+1+0+1+0+0+0+0)/5 = 2/5\n",
    "\n",
    "Jaccard (A,C) = (0+0+0+1+0+0+1+0)/6 = 2/6 = 1/3\n",
    "\n",
    "Jaccard (B,C) = (0+0+0+1+0+0+0+0)/6 = 1/6\n",
    "\n",
    "\n",
    "\n",
    "(d)\n",
    "Cosine (A,B) = 2/sqrt(4) * sqrt(3) = 1/sqrt(3)\n",
    "\n",
    "Cosine (A,C) = 2/sqrt(4) * sqrt(4) = 1/2\n",
    "\n",
    "Cosine (B,C) = 1/sqrt(3) * sqrt(4) = 1/(2 * sqrt (3))\n",
    "\n",
    "(e)\n",
    "\n",
    "    a   b   c   d   e   f   g   h\n",
    "    \n",
    "    4   5       5   1       3   2    A (avg = 3.33)\n",
    "    \n",
    "        3   4   3       1   2   1    B (avg = 2.33)\n",
    "        \n",
    "    2       1   3       4   5   3    C (avg = 3)\n",
    "    \n",
    "    a      b       c     d      e     f        g       h\n",
    "    \n",
    "    0.67   1.67        1.67   -2.33          -0.33   -1.33    A\n",
    "    \n",
    "           0.67  1.67  0.67   -1.33  -0.33   -1.33            B\n",
    "        \n",
    "    -1             -2    0            1        2       0      C\n",
    "\n",
    "\n",
    "\n",
    "(f)\n",
    "Cosine(A,B) = (1.67 x 0.67 + 1.67 x 0.67 + 2.33 x 1.33  + 0.33 x 1.33)/sqrt(0.67 x 0.67 + 1.67 x 1.67 + 1.67 x 1.67 + 2.33 x 2.33 + 0.33 x 0.33 + 1.33  x 1.33) x sqrt(0.67^2 + 1.67^2 + 0.67^2 + 1.33^2 + 0.33^2 + 1.33^2) = 0.58\n",
    "\n",
    "Cosine(A,C) = (0.67 x (-1) - 0.33 x 2)/sqrt(0.67 x 0.67 + 1.67 x 1.67 + 1.67 x 1.67 + 2.33 x 2.33 + 0.33 x 0.33 + 1.33 x 1.33) x sqrt(1^2 + 2^2 + 1^2 + 2^2) = -0.11\n",
    "\n",
    "Cosine(B,C) = (1.67 x (-2) - 0.33 x 1 - 1.33 x 2)/sqrt(0.67^2 + 1.67^2 + 0.67^2 + 1.33^2 + 0.33^2 + 1.33^2) * sqrt(1^2 + 2^2 + 1^2 + 2^2) = -0.739\n",
    "\n",
    "\n",
    "\n",
    "(g) Cosine Similarity is better than Jaccard because Jaccard treats every rating as 1 while treats others as 0 which the user did not rate (ignores the value of rating). Cosine similarity takes into account the value of rating and normalizes them which provides a better result. Cosine Similarity also works for arbitrary vectors unlike Jaccard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
